{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -qq install logfire\n",
    "!pip -qq install nest_asyncio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -qq install pydantic-ai pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04:01:20.253 counting size of cwd=c:\\Users\\rupak\\OneDrive\\Documents\\Logfire\n",
      "04:01:20.255   reading log.py\n",
      "04:01:20.263   reading logipynb.ipynb\n",
      "04:01:20.273   reading test.ipynb\n",
      "04:01:20.279   total size of c:\\Users\\rupak\\OneDrive\\Documents\\Logfire is 6229 bytes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mLogfire\u001b[0m project URL: \u001b[4;36mhttps://logfire.pydantic.dev/rupak182/test\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import logfire\n",
    "from pathlib import Path\n",
    "\n",
    "logfire.configure()\n",
    "\n",
    "\n",
    "cwd = Path.cwd()\n",
    "total_size =0\n",
    "\n",
    "\n",
    "with logfire.span('counting size of {cwd=}', cwd=cwd):\n",
    "    for path in cwd.iterdir():\n",
    "        if path.is_file():\n",
    "            with logfire.span('reading {path}',path= path.relative_to(cwd)):\n",
    "                total_size+= len(path.read_bytes())\n",
    "\n",
    "    logfire.info('total size of {cwd} is {size} bytes',cwd=cwd,size=total_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in c:\\users\\rupak\\onedrive\\documents\\logfire\\.venv\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\rupak\\onedrive\\documents\\logfire\\.venv\\lib\\site-packages (1.6.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install python-dotenv\n",
    "!pip install nest-asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio \n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rich in c:\\users\\rupak\\onedrive\\documents\\logfire\\.venv\\lib\\site-packages (13.9.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\rupak\\onedrive\\documents\\logfire\\.venv\\lib\\site-packages (from rich) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\rupak\\onedrive\\documents\\logfire\\.venv\\lib\\site-packages (from rich) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\rupak\\onedrive\\documents\\logfire\\.venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install rich\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print as pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model gemini-1.5-flash\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Logfire</span> project URL: <a href=\"https://logfire.pydantic.dev/rupak182/test\" target=\"_blank\"><span style=\"color: #008080; text-decoration-color: #008080; text-decoration: underline\">https://logfire.pydantic.dev/rupak182/test</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mLogfire\u001b[0m project URL: \u001b]8;id=953702;https://logfire.pydantic.dev/rupak182/test\u001b\\\u001b[4;36mhttps://logfire.pydantic.dev/rupak182/test\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06:36:18.542 agent run prompt=The windy city in the US of A.\n",
      "06:36:18.544   preparing model and tools run_step=1\n",
      "06:36:18.545   model request\n",
      "06:36:20.437   handle model response\n",
      "city='Chicago' country='USA'\n",
      "Usage(requests=1, request_tokens=60, response_tokens=7, total_tokens=67, details=None)\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "from typing import cast\n",
    "\n",
    "import logfire\n",
    "from pydantic import BaseModel\n",
    "from pydantic_ai import Agent\n",
    "from pydantic_ai.models import KnownModelName\n",
    "\n",
    "logfire.configure(send_to_logfire='if-token-present')\n",
    "\n",
    "\n",
    "class MyModel(BaseModel):\n",
    "    city:str\n",
    "    country:str\n",
    "\n",
    "model =cast(KnownModelName, os.getenv('PYDANTIC_AI_MODEL','groq:llama-3.3-70b-versatile'))\n",
    "print(f'Using model {model}')\n",
    "agent =Agent(model,result_type=MyModel)\n",
    "\n",
    "result= agent.run_sync('The windy city in the US of A.')\n",
    "print(result.data)\n",
    "print(result.usage())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weather Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13:52:02.984 weather_agent run prompt=What is the weather like in London and in Wiltshire\n",
      "13:52:02.985   preparing model and tools run_step=1\n",
      "13:52:02.986   model request\n",
      "13:52:04.276   handle model response\n",
      "13:52:04.278     running tools=['get_lat_lng', 'get_lat_lng', 'get_weather', 'get_weather']\n",
      "13:52:04.280   preparing model and tools run_step=2\n",
      "13:52:04.280   model request\n",
      "13:52:04.878   handle model response\n",
      "Response. The weather in London is sunny with a temperature of 21 °C and the weather in Wiltshire is also sunny with a temperature of 21 °C.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations as _annotations\n",
    "\n",
    "import os \n",
    "from dataclasses import dataclass\n",
    "from typing import Any\n",
    "\n",
    "import logfire\n",
    "from httpx import AsyncClient\n",
    "\n",
    "from pydantic_ai import Agent,ModelRetry,RunContext\n",
    "\n",
    "logfire.configure()\n",
    "\n",
    "@dataclass \n",
    "class Deps:\n",
    "    client:AsyncClient\n",
    "    weather_api_key:str|None\n",
    "    geo_api_key:str|None\n",
    "\n",
    "weather_agent = Agent(\n",
    "    'groq:llama-3.1-70b-versatile',\n",
    "    \n",
    "    system_prompt=(\n",
    "        'Be concise ,reply in one sentence '\n",
    "        'Use the `get_lat_lng tool` to get the longitude and latitude of the locations'\n",
    "        'then use the `get_weather` tool to get the weather'\n",
    "        'Use the results even if they are inaccuarate'\n",
    "    ),\n",
    "\n",
    "    deps_type=Deps,\n",
    "    retries=2\n",
    ")\n",
    "\n",
    "@weather_agent.tool\n",
    "async def get_lat_lng(\n",
    "    ctx:RunContext[Deps], location_description:str\n",
    ") -> dict[str,float]:\n",
    "    \n",
    "    \"\"\"Get the latitude and longitude of a location\n",
    "        Args:\n",
    "        ctx:The context\n",
    "        location_Description:A description of the location\n",
    "    \"\"\"\n",
    "\n",
    "    if ctx.deps.geo_api_key is None or ctx.deps.geo_api_key==\"\":\n",
    "        return {'lat':51.1, 'lng': -0.2}\n",
    "\n",
    "    print(ctx.deps.geo_api_key)\n",
    "    params = {\n",
    "        'q':location_description,\n",
    "        'api_key':ctx.deps.geo_api_key\n",
    "    }\n",
    "\n",
    "    with logfire.span('calling geocode API', params=params) as span:\n",
    "        r= await ctx.deps.client.get('https://geocode.maps.co/search', params=params)\n",
    "        r.raise_for_status\n",
    "        data = r.json()\n",
    "        span.set_attribute('response',data)\n",
    "\n",
    "    if data:\n",
    "        return {'lat': data[0]['lat'], 'lng':data[0]['lon']}\n",
    "    else:\n",
    "        raise ModelRetry('Could not find the location')\n",
    "\n",
    "@weather_agent.tool\n",
    "async def get_weather(ctx:RunContext[Deps],lat:float,lng:float)->dict[str,any]:\n",
    "    \"\"\"\n",
    "        Get the weather at a location.\n",
    "\n",
    "        Args:\n",
    "            ctx:The Context\n",
    "            lat:Latitude of the location\n",
    "            lng: Longitude of the location\n",
    "    \"\"\"\n",
    "    if ctx.deps.weather_api_key is None or ctx.deps.weather_api_key==\"\":\n",
    "        return {'temperature': '21 °C', 'description': 'Sunny'}\n",
    "    \n",
    "    print(ctx.deps.weather_api_key)\n",
    "\n",
    "\n",
    "    params ={\n",
    "        'apikey' : ctx.deps.weather_api_key,\n",
    "        'location':f'{lat},{lng}',\n",
    "        'units':'metric'\n",
    "    }\n",
    "\n",
    "    with logfire.span('Calling weather API', params = params) as span:\n",
    "        r= await ctx.deps.client.get(\n",
    "        'https://api.tomorrow.io/v4/weather/realtime', params=params           \n",
    "        )\n",
    "    r.raise_for_status()\n",
    "    data = r.json()\n",
    "    span.set_attribute('response',data)\n",
    "\n",
    "    values = data['data']['values']\n",
    "\n",
    "    code_lookup = {\n",
    "        1000: 'Clear, Sunny',\n",
    "        1100: 'Mostly Clear',\n",
    "        1101: 'Partly Cloudy',\n",
    "        1102: 'Mostly Cloudy',\n",
    "        1001: 'Cloudy',\n",
    "        2000: 'Fog',\n",
    "        2100: 'Light Fog',\n",
    "        4000: 'Drizzle',\n",
    "        4001: 'Rain',\n",
    "        4200: 'Light Rain',\n",
    "        4201: 'Heavy Rain',\n",
    "        5000: 'Snow',\n",
    "        5001: 'Flurries',\n",
    "        5100: 'Light Snow',\n",
    "        5101: 'Heavy Snow',\n",
    "        6000: 'Freezing Drizzle',\n",
    "        6001: 'Freezing Rain',\n",
    "        6200: 'Light Freezing Rain',\n",
    "        6201: 'Heavy Freezing Rain',\n",
    "        7000: 'Ice Pellets',\n",
    "        7101: 'Heavy Ice Pellets',\n",
    "        7102: 'Light Ice Pellets',\n",
    "        8000: 'Thunderstorm',\n",
    "    }\n",
    "\n",
    "    return {\n",
    "        'temperature': f'{values[\"tempertureApparent\"]:0.0f}°C',\n",
    "        'description':code_lookup.get(values['weatherCode'],'Unknown')\n",
    "    }\n",
    "\n",
    "\n",
    "async def main():\n",
    "    async with AsyncClient() as client:\n",
    "        weather_api_key= os.getenv('WEATHER_API_KEY'),\n",
    "        geo_api_key= os.getenv('GEO_API_KEY')\n",
    "\n",
    "        deps = Deps(\n",
    "            client=client,\n",
    "            weather_api_key=None,\n",
    "            geo_api_key=None\n",
    "        )\n",
    "\n",
    "        result = await weather_agent.run(\n",
    "            'What is the weather like in London and in Wiltshire',\n",
    "            model_settings={\"temperature\":0.0},\n",
    "            deps=deps,\n",
    "        )\n",
    "\n",
    "        print('Response.',result.data)\n",
    "\n",
    "await main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bank Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14:15:13.829 support_agent run prompt=What is the balance\n",
      "14:15:13.829   preparing model and tools run_step=1\n",
      "14:15:13.830   model request\n",
      "14:15:15.644   handle model response\n",
      "14:15:15.645     running tools=['customer_balance']\n",
      "14:15:15.646   preparing model and tools run_step=2\n",
      "14:15:15.646   model request\n",
      "14:15:16.531   handle model response\n",
      "14:15:16.532   preparing model and tools run_step=3\n",
      "14:15:16.533   model request\n",
      "14:15:17.519   handle model response\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SupportResult</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">support_advice</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Your balance is $123.44.'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">block_card</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #808000; text-decoration-color: #808000\">risk</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mSupportResult\u001b[0m\u001b[1m(\u001b[0m\u001b[33msupport_advice\u001b[0m=\u001b[32m'Your balance is $123.44.'\u001b[0m, \u001b[33mblock_card\u001b[0m=\u001b[3;91mFalse\u001b[0m, \u001b[33mrisk\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14:15:17.530 support_agent run prompt=lost the card\n",
      "14:15:17.530   preparing model and tools run_step=1\n",
      "14:15:17.531   model request\n",
      "14:15:18.535   handle model response\n",
      "14:15:18.536   preparing model and tools run_step=2\n",
      "14:15:18.536   model request\n",
      "14:15:19.551   handle model response\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SupportResult</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">support_advice</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'I am sorry to hear that you lost your card. I have blocked your card as a precaution. Please </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">contact us to request a new card.'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">block_card</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">risk</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mSupportResult\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33msupport_advice\u001b[0m=\u001b[32m'I am sorry to hear that you lost your card. I have blocked your card as a precaution. Please \u001b[0m\n",
       "\u001b[32mcontact us to request a new card.'\u001b[0m,\n",
       "    \u001b[33mblock_card\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
       "    \u001b[33mrisk\u001b[0m=\u001b[1;36m0\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "from pydantic import BaseModel,Field\n",
    "from pydantic_ai import Agent,RunContext\n",
    "\n",
    "\n",
    "class DatabaseConn:\n",
    "    @classmethod\n",
    "    async def customer_name(cls,*,id:int)->str|None:\n",
    "        if id == 123:\n",
    "            return 'John'\n",
    "    @classmethod\n",
    "    async def customer_balance(cls,*,id:int,include_pending:bool)->float:\n",
    "        if id ==123:\n",
    "            return 123.44\n",
    "        else:\n",
    "            raise ValueError('Customer not found')\n",
    "        \n",
    "@dataclass\n",
    "class SupportDependencies:\n",
    "    customer_id:int\n",
    "    db:DatabaseConn\n",
    "\n",
    "class SupportResult(BaseModel):\n",
    "    support_advice:str =Field(description='Advice returned to the customer')\n",
    "    block_card:bool= Field(description='Whether to block the card')\n",
    "    risk:int = Field(description='Risk level of query', ge=0, le=0)\n",
    "\n",
    "support_agent= Agent(\n",
    "    'gemini-1.5-flash',\n",
    "    deps_type=SupportDependencies,\n",
    "    result_type=SupportResult,\n",
    "    system_prompt=(\n",
    "        'You are a support agent in a bank, give the customer'\n",
    "        'support and judge the risk level of the query.'\n",
    "        \"Reply using the customer's name.\"\n",
    "    )\n",
    ")\n",
    "\n",
    "@support_agent.tool\n",
    "async def customer_balance(\n",
    "    ctx:RunContext[SupportDependencies], include_pending:bool\n",
    ")->str:\n",
    "    balance= await ctx.deps.db.customer_balance(\n",
    "        id= ctx.deps.customer_id,\n",
    "        include_pending=include_pending\n",
    "    )\n",
    "    return f'${balance:.2f}'\n",
    "\n",
    "deps = SupportDependencies(customer_id=123,db=DatabaseConn())\n",
    "result = support_agent.run_sync('What is the balance', deps= deps)\n",
    "pprint(result.data)\n",
    "\n",
    "\n",
    "result = support_agent.run_sync('lost the card',deps = deps)\n",
    "pprint(result.data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting asyncpg\n",
      "  Downloading asyncpg-0.30.0-cp311-cp311-win_amd64.whl.metadata (5.2 kB)\n",
      "Downloading asyncpg-0.30.0-cp311-cp311-win_amd64.whl (629 kB)\n",
      "   ---------------------------------------- 0.0/629.4 kB ? eta -:--:--\n",
      "   ---------------- ----------------------- 262.1/629.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 629.4/629.4 kB 1.6 MB/s eta 0:00:00\n",
      "Installing collected packages: asyncpg\n",
      "Successfully installed asyncpg-0.30.0\n"
     ]
    }
   ],
   "source": [
    "!pip install asyncpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting devtools\n",
      "  Downloading devtools-0.12.2-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting asttokens<3.0.0,>=2.0.0 (from devtools)\n",
      "  Downloading asttokens-2.4.1-py2.py3-none-any.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: executing>=1.1.1 in c:\\users\\rupak\\onedrive\\documents\\logfire\\.venv\\lib\\site-packages (from devtools) (2.1.0)\n",
      "Requirement already satisfied: pygments>=2.15.0 in c:\\users\\rupak\\onedrive\\documents\\logfire\\.venv\\lib\\site-packages (from devtools) (2.18.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\rupak\\onedrive\\documents\\logfire\\.venv\\lib\\site-packages (from asttokens<3.0.0,>=2.0.0->devtools) (1.17.0)\n",
      "Downloading devtools-0.12.2-py3-none-any.whl (19 kB)\n",
      "Downloading asttokens-2.4.1-py2.py3-none-any.whl (27 kB)\n",
      "Installing collected packages: asttokens, devtools\n",
      "  Attempting uninstall: asttokens\n",
      "    Found existing installation: asttokens 3.0.0\n",
      "    Uninstalling asttokens-3.0.0:\n",
      "      Successfully uninstalled asttokens-3.0.0\n",
      "Successfully installed asttokens-2.4.1 devtools-0.12.2\n"
     ]
    }
   ],
   "source": [
    "!pip install devtools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: logfire[asyncpg] in c:\\users\\rupak\\onedrive\\documents\\logfire\\.venv\\lib\\site-packages (2.11.1)\n",
      "Requirement already satisfied: executing>=2.0.1 in c:\\users\\rupak\\onedrive\\documents\\logfire\\.venv\\lib\\site-packages (from logfire[asyncpg]) (2.1.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-http>=1.21.0 in c:\\users\\rupak\\onedrive\\documents\\logfire\\.venv\\lib\\site-packages (from logfire[asyncpg]) (1.29.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation>=0.41b0 in c:\\users\\rupak\\onedrive\\documents\\logfire\\.venv\\lib\\site-packages (from logfire[asyncpg]) (0.50b0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.21.0 in c:\\users\\rupak\\onedrive\\documents\\logfire\\.venv\\lib\\site-packages (from logfire[asyncpg]) (1.29.0)\n",
      "Requirement already satisfied: protobuf>=4.23.4 in c:\\users\\rupak\\onedrive\\documents\\logfire\\.venv\\lib\\site-packages (from logfire[asyncpg]) (5.29.2)\n",
      "Requirement already satisfied: rich>=13.4.2 in c:\\users\\rupak\\onedrive\\documents\\logfire\\.venv\\lib\\site-packages (from logfire[asyncpg]) (13.9.4)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in c:\\users\\rupak\\onedrive\\documents\\logfire\\.venv\\lib\\site-packages (from logfire[asyncpg]) (4.12.2)\n",
      "Collecting opentelemetry-instrumentation-asyncpg>=0.42b0 (from logfire[asyncpg])\n",
      "  Downloading opentelemetry_instrumentation_asyncpg-0.50b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in c:\\users\\rupak\\onedrive\\documents\\logfire\\.venv\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-http>=1.21.0->logfire[asyncpg]) (1.2.15)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in c:\\users\\rupak\\onedrive\\documents\\logfire\\.venv\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-http>=1.21.0->logfire[asyncpg]) (1.66.0)\n",
      "Requirement already satisfied: opentelemetry-api~=1.15 in c:\\users\\rupak\\onedrive\\documents\\logfire\\.venv\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-http>=1.21.0->logfire[asyncpg]) (1.29.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.29.0 in c:\\users\\rupak\\onedrive\\documents\\logfire\\.venv\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-http>=1.21.0->logfire[asyncpg]) (1.29.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.29.0 in c:\\users\\rupak\\onedrive\\documents\\logfire\\.venv\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-http>=1.21.0->logfire[asyncpg]) (1.29.0)\n",
      "Requirement already satisfied: requests~=2.7 in c:\\users\\rupak\\onedrive\\documents\\logfire\\.venv\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-http>=1.21.0->logfire[asyncpg]) (2.32.3)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.50b0 in c:\\users\\rupak\\onedrive\\documents\\logfire\\.venv\\lib\\site-packages (from opentelemetry-instrumentation>=0.41b0->logfire[asyncpg]) (0.50b0)\n",
      "Requirement already satisfied: packaging>=18.0 in c:\\users\\rupak\\onedrive\\documents\\logfire\\.venv\\lib\\site-packages (from opentelemetry-instrumentation>=0.41b0->logfire[asyncpg]) (24.2)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in c:\\users\\rupak\\onedrive\\documents\\logfire\\.venv\\lib\\site-packages (from opentelemetry-instrumentation>=0.41b0->logfire[asyncpg]) (1.17.0)\n",
      "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in c:\\users\\rupak\\onedrive\\documents\\logfire\\.venv\\lib\\site-packages (from opentelemetry-api~=1.15->opentelemetry-exporter-otlp-proto-http>=1.21.0->logfire[asyncpg]) (8.5.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\rupak\\onedrive\\documents\\logfire\\.venv\\lib\\site-packages (from rich>=13.4.2->logfire[asyncpg]) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\rupak\\onedrive\\documents\\logfire\\.venv\\lib\\site-packages (from rich>=13.4.2->logfire[asyncpg]) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\rupak\\onedrive\\documents\\logfire\\.venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=13.4.2->logfire[asyncpg]) (0.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rupak\\onedrive\\documents\\logfire\\.venv\\lib\\site-packages (from requests~=2.7->opentelemetry-exporter-otlp-proto-http>=1.21.0->logfire[asyncpg]) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rupak\\onedrive\\documents\\logfire\\.venv\\lib\\site-packages (from requests~=2.7->opentelemetry-exporter-otlp-proto-http>=1.21.0->logfire[asyncpg]) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rupak\\onedrive\\documents\\logfire\\.venv\\lib\\site-packages (from requests~=2.7->opentelemetry-exporter-otlp-proto-http>=1.21.0->logfire[asyncpg]) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rupak\\onedrive\\documents\\logfire\\.venv\\lib\\site-packages (from requests~=2.7->opentelemetry-exporter-otlp-proto-http>=1.21.0->logfire[asyncpg]) (2024.12.14)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\rupak\\onedrive\\documents\\logfire\\.venv\\lib\\site-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api~=1.15->opentelemetry-exporter-otlp-proto-http>=1.21.0->logfire[asyncpg]) (3.21.0)\n",
      "Downloading opentelemetry_instrumentation_asyncpg-0.50b0-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: opentelemetry-instrumentation-asyncpg\n",
      "Successfully installed opentelemetry-instrumentation-asyncpg-0.50b0\n"
     ]
    }
   ],
   "source": [
    "!pip install logfire[asyncpg]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQL QUERY AGENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attempting to instrument while already instrumented\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17:54:55.178 check and create DB\n",
      "17:54:55.209   SELECT\n",
      "17:54:55.249 create schema\n",
      "17:54:55.249   BEGIN;\n",
      "17:54:55.250   COMMIT;\n",
      "17:54:55.251 agent run prompt=show me logs from yesterday, with level \"error\"\n",
      "17:54:55.251   preparing model and tools run_step=1\n",
      "17:54:55.252   model request\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Logfire</span> project URL: <a href=\"https://logfire.pydantic.dev/rupak182/test\" target=\"_blank\"><span style=\"color: #008080; text-decoration-color: #008080; text-decoration: underline\">https://logfire.pydantic.dev/rupak182/test</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mLogfire\u001b[0m project URL: \u001b]8;id=388652;https://logfire.pydantic.dev/rupak182/test\u001b\\\u001b[4;36mhttps://logfire.pydantic.dev/rupak182/test\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17:54:56.038   handle model response\n",
      "17:54:56.039     Explain\n",
      "C:\\Users\\rupak\\AppData\\Local\\Temp\\ipykernel_25016\\790407777.py:118 main\n",
      "    result.all_messages(): [\n",
      "        ModelRequest(\n",
      "            parts=[\n",
      "                SystemPromptPart(\n",
      "                    content=(\n",
      "                        'Given the following PostgreSQL table of records, your job is to\\n'\n",
      "                        \"write a sql query that suits the user's request\\n\"\n",
      "                        '\\n'\n",
      "                        'Database schema:\\n'\n",
      "                        '\\n'\n",
      "                        'CREATE TABLE records (\\n'\n",
      "                        '    created_at timestamptz,\\n'\n",
      "                        '    start_timestamp timestamptz,\\n'\n",
      "                        '    end_timestamp timestamptz,\\n'\n",
      "                        '    trace_id text,\\n'\n",
      "                        '    span_id text,\\n'\n",
      "                        '    parent_span_id text,\\n'\n",
      "                        '    level log_level,\\n'\n",
      "                        '    span_name text,\\n'\n",
      "                        '    message text,\\n'\n",
      "                        '    attributes_json_schema text,\\n'\n",
      "                        '    attributes jsonb,\\n'\n",
      "                        '    tags text[],\\n'\n",
      "                        '    is_exception boolean,\\n'\n",
      "                        '    otel_status_message text,\\n'\n",
      "                        '    service_name text\\n'\n",
      "                        ');\\n'\n",
      "                        '\\n'\n",
      "                        '\\n'\n",
      "                        \"today's date = 2025-01-01\\n\"\n",
      "                        '\\n'\n",
      "                        'Example\\n'\n",
      "                        '    request: show me records where foobar is false\\n'\n",
      "                        \"    response: SELECT * FROM records WHERE attributes->>'foobar' = false\\n\"\n",
      "                        'Example\\n'\n",
      "                        '    request: show me records where attributes include the key \"foobar\"\\n'\n",
      "                        \"    response: SELECT * FROM records WHERE attributes ? 'foobar'\\n\"\n",
      "                        'Example\\n'\n",
      "                        '    request: show me records from yesterday\\n'\n",
      "                        '    response: SELECT * FROM records WHERE start_timestamp::date > CURRENT_TIMESTAMP - INTERVA'\n",
      "                        \"L '1 day'\\n\"\n",
      "                        'Example\\n'\n",
      "                        '    request: show me error records with the tag \"foobar\"\\n'\n",
      "                        \"    response: SELECT * FROM records WHERE level = 'error' and 'foobar' = ANY(tags)\\n\"\n",
      "                    ),\n",
      "                    part_kind='system-prompt',\n",
      "                ),\n",
      "                UserPromptPart(\n",
      "                    content='show me logs from yesterday, with level \"error\"',\n",
      "                    timestamp=datetime.datetime(2025, 1, 1, 17, 54, 55, 251657, tzinfo=datetime.timezone.utc),\n",
      "                    part_kind='user-prompt',\n",
      "                ),\n",
      "            ],\n",
      "            kind='request',\n",
      "        ),\n",
      "        ModelResponse(\n",
      "            parts=[\n",
      "                ToolCallPart(\n",
      "                    tool_name='final_result_Success',\n",
      "                    args=ArgsJson(\n",
      "                        args_json=(\n",
      "                            '{\"explaination\": \"To show logs from yesterday with level \\'error\\', we need to filter the r'\n",
      "                            'ecords table by the start_timestamp and level columns. The start_timestamp column is filt'\n",
      "                            \"ered to get yesterday's date by using CURRENT_TIMESTAMP - INTERVAL '1 day'. The level col\"\n",
      "                            'umn is filtered to get only \\'error\\' level logs.\", \"sql_query\": \"SELECT * FROM records WHE'\n",
      "                            'RE start_timestamp::date = CURRENT_TIMESTAMP - INTERVAL \\'1 day\\' AND level = \\'error\\'\"}'\n",
      "                        ),\n",
      "                    ),\n",
      "                    tool_call_id='call_655z',\n",
      "                    part_kind='tool-call',\n",
      "                ),\n",
      "            ],\n",
      "            timestamp=datetime.datetime(2025, 1, 1, 17, 55, 3, tzinfo=datetime.timezone.utc),\n",
      "            kind='response',\n",
      "        ),\n",
      "        ModelRequest(\n",
      "            parts=[\n",
      "                ToolReturnPart(\n",
      "                    tool_name='final_result_Success',\n",
      "                    content='Final result processed.',\n",
      "                    tool_call_id='call_655z',\n",
      "                    timestamp=datetime.datetime(2025, 1, 1, 17, 54, 56, 43650, tzinfo=datetime.timezone.utc),\n",
      "                    part_kind='tool-return',\n",
      "                ),\n",
      "            ],\n",
      "            kind='request',\n",
      "        ),\n",
      "    ] (list) len=3\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from collections.abc  import AsyncGenerator\n",
    "from contextlib import asynccontextmanager\n",
    "from dataclasses import dataclass\n",
    "from datetime import date\n",
    "from typing import Annotated,Any,Union\n",
    "from devtools import debug\n",
    "\n",
    "import asyncpg\n",
    "import logfire\n",
    "from annotated_types import MinLen\n",
    "from pydantic import BaseModel,Field\n",
    "from typing_extensions import TypeAlias\n",
    "\n",
    "\n",
    "from pydantic_ai import Agent, ModelRetry,RunContext\n",
    "\n",
    "logfire.configure(send_to_logfire=\"if-token-present\")\n",
    "logfire.instrument_asyncpg()\n",
    "\n",
    "DB_SCHEMA = \"\"\"\n",
    "CREATE TABLE records (\n",
    "    created_at timestamptz,\n",
    "    start_timestamp timestamptz,\n",
    "    end_timestamp timestamptz,\n",
    "    trace_id text,\n",
    "    span_id text,\n",
    "    parent_span_id text,\n",
    "    level log_level,\n",
    "    span_name text,\n",
    "    message text,\n",
    "    attributes_json_schema text,\n",
    "    attributes jsonb,\n",
    "    tags text[],\n",
    "    is_exception boolean,\n",
    "    otel_status_message text,\n",
    "    service_name text\n",
    ");\n",
    "\"\"\"\n",
    "@dataclass\n",
    "class Deps:\n",
    "    conn:asyncpg.connection\n",
    "\n",
    "\n",
    "class Success(BaseModel):\n",
    "    \"\"\"Response when SQL could be successfully generated\"\"\"\n",
    "    \n",
    "    sql_query: Annotated[str,MinLen(1)]\n",
    "    explaination:str = Field('',description=\"Explaination of the sql query as markdown\")\n",
    "\n",
    "class InvalidRequest(BaseModel):\n",
    "    \"\"\"Response when the user input didn't include enought info to generate SQL\"\"\"\n",
    "    error_message:str\n",
    "\n",
    "Response:TypeAlias = Union[Success,InvalidRequest]\n",
    "\n",
    "agent:Agent[Deps,Response] =Agent(\n",
    "    'groq:llama-3.1-70b-versatile',\n",
    "    result_type=Response,\n",
    "    deps_type=Deps\n",
    ")\n",
    "\n",
    "\n",
    "@agent.system_prompt\n",
    "async def system_prompt() ->str:\n",
    "    return f\"\"\"\\\n",
    "Given the following PostgreSQL table of records, your job is to\n",
    "write a sql query that suits the user's request\n",
    "\n",
    "Database schema:\n",
    "{DB_SCHEMA}\n",
    "\n",
    "today's date = {date.today()}\n",
    "\n",
    "Example\n",
    "    request: show me records where foobar is false\n",
    "    response: SELECT * FROM records WHERE attributes->>'foobar' = false\n",
    "Example\n",
    "    request: show me records where attributes include the key \"foobar\"\n",
    "    response: SELECT * FROM records WHERE attributes ? 'foobar'\n",
    "Example\n",
    "    request: show me records from yesterday\n",
    "    response: SELECT * FROM records WHERE start_timestamp::date > CURRENT_TIMESTAMP - INTERVAL '1 day'\n",
    "Example\n",
    "    request: show me error records with the tag \"foobar\"\n",
    "    response: SELECT * FROM records WHERE level = 'error' and 'foobar' = ANY(tags)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "@agent.result_validator\n",
    "async def validate_result(ctx:RunContext[Deps], result:Response)->Response:\n",
    "    if isinstance(result,InvalidRequest):\n",
    "        return result\n",
    "    \n",
    "    result.sql_query =result.sql_query.replace(\"\\\\\",\"\")\n",
    "\n",
    "    if not result.sql_query.upper().startswith('SELECT'):\n",
    "        raise ModelRetry('Please create a SELECT query')\n",
    "\n",
    "    try:\n",
    "        await ctx.deps.conn.execute(f'Explain {result.sql_query}')  # validaiting syntax\n",
    "    except asyncpg.exceptions.PostgresError as e:\n",
    "        raise ModelRetry(f'Invalid query: {e}') from e\n",
    "    else:\n",
    "        return result\n",
    "    \n",
    "\n",
    "async def main():\n",
    "    prompt = 'show me logs from yesterday, with level \"error\"'\n",
    "    #prompt=sys.argv[1]\n",
    "\n",
    "    async with database_connect(\n",
    "        'postgresql://postgres:mysecretpassword@localhost:5433','sql_gen'\n",
    "    ) as conn:\n",
    "        deps = Deps(conn)\n",
    "        result = await agent.run(prompt,deps=deps)\n",
    "    \n",
    "    debug(result.all_messages())\n",
    "\n",
    "@asynccontextmanager\n",
    "async def database_connect(server_dsn:str, database:str)-> AsyncGenerator[Any,None]:\n",
    "    with logfire.span('check and create DB'):\n",
    "        conn= await asyncpg.connect(server_dsn)\n",
    "        try:\n",
    "            db_exists= await conn.fetchval(\n",
    "                'SELECT 1 FROM pg_database where datname = $1',database\n",
    "            )\n",
    "\n",
    "            if not db_exists:\n",
    "                await conn.execute(f'CREATE DATABASE {database}')\n",
    "        \n",
    "        finally:\n",
    "            await conn.close()\n",
    "        \n",
    "    \n",
    "    conn = await asyncpg.connect(f'{server_dsn}/{database}')\n",
    "    try:\n",
    "        with logfire.span('create schema'):\n",
    "            async with conn.transaction():\n",
    "                if not db_exists:\n",
    "                    await conn.execute(\n",
    "                        \"CREATE TYPE log_level as ENUM('debug', 'info' , 'warning' , 'error', 'critical') \"\n",
    "                    )\n",
    "                    await conn.execute(DB_SCHEMA)\n",
    "        yield conn   # control back to caller till it finishes\n",
    "    finally:\n",
    "        await conn.close()\n",
    "\n",
    "await main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Yielding Control:\n",
    "By using yield, the function can pause its execution and return control to the caller while still maintaining its state. This allows the caller to use the resource (in this case, the database connection) within a with statement.\n",
    "When the caller exits the context (i.e., when the block under the with statement is done), execution resumes after the yield, allowing for any necessary cleanup (like closing the connection)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flight Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11:00:59.962 search_agent run prompt=Find me a flight from SFO to ANC on 2025-01-10\n",
      "11:00:59.964   preparing model and tools run_step=1\n",
      "11:00:59.964   model request\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Logfire</span> project URL: <a href=\"https://logfire.pydantic.dev/rupak182/test\" target=\"_blank\"><span style=\"color: #008080; text-decoration-color: #008080; text-decoration: underline\">https://logfire.pydantic.dev/rupak182/test</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mLogfire\u001b[0m project URL: \u001b]8;id=191353;https://logfire.pydantic.dev/rupak182/test\u001b\\\u001b[4;36mhttps://logfire.pydantic.dev/rupak182/test\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11:01:01.121   handle model response\n",
      "11:01:01.122     running tools=['extract_flights']\n",
      "11:01:01.122     extraction_agent run prompt=\n",
      "1. Flight SFO-AK123\n",
      "- Price: $350\n",
      "- Origin: San Francisco Int... Bush Intercontinental Airport (IAH)\n",
      "- Date: January 10, 2025\n",
      "\n",
      "11:01:01.123       preparing model and tools run_step=1\n",
      "11:01:01.123       model request\n",
      "11:01:02.834       handle model response\n",
      "11:01:02.853     Found 8\n",
      "11:01:02.854   preparing model and tools run_step=2\n",
      "11:01:02.855   model request\n",
      "11:01:03.535   handle model response\n",
      "Flight found: flight_number='NYC-LA101' price='$250' origin='SFO' destination='ANC' date=datetime.date(2025, 1, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Do you want to confirm this flight or keep searching? (confirm/search): </pre>\n"
      ],
      "text/plain": [
       "Do you want to confirm this flight or keep searching? (confirm/search): "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11:01:03.550 search_agent run prompt=Find me a flight from SFO to ANC on 2025-01-10\n",
      "11:01:03.551   preparing model and tools run_step=1\n",
      "11:01:03.551   model request\n",
      "11:01:04.129   handle model response\n",
      "Flight found: flight_number='AA101' price='500' origin='SFO' destination='ANC' date=datetime.date(2025, 1, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Do you want to confirm this flight or keep searching? (confirm/search): </pre>\n"
      ],
      "text/plain": [
       "Do you want to confirm this flight or keep searching? (confirm/search): "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11:01:14.829 search_agent run prompt=Find me a flight from SFO to ANC on 2025-01-10\n",
      "11:01:14.829   preparing model and tools run_step=1\n",
      "11:01:14.830   model request\n",
      "11:01:15.465   handle model response\n",
      "11:01:15.465     running tools=['extract_flights']\n",
      "11:01:15.466     extraction_agent run prompt=\n",
      "1. Flight SFO-AK123\n",
      "- Price: $350\n",
      "- Origin: San Francisco Int... Bush Intercontinental Airport (IAH)\n",
      "- Date: January 10, 2025\n",
      "\n",
      "11:01:15.467       preparing model and tools run_step=1\n",
      "11:01:15.467       model request\n",
      "11:01:17.119       handle model response\n",
      "11:01:17.122     Found 8\n",
      "11:01:17.123   preparing model and tools run_step=2\n",
      "11:01:17.123   model request\n",
      "11:01:17.798   handle model response\n",
      "Flight found: flight_number='NYC-LA101' price='$250' origin='SFO' destination='ANC' date=datetime.date(2025, 1, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Do you want to confirm this flight or keep searching? (confirm/search): </pre>\n"
      ],
      "text/plain": [
       "Do you want to confirm this flight or keep searching? (confirm/search): "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">What seat would you like?: </pre>\n"
      ],
      "text/plain": [
       "What seat would you like?: "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11:01:36.773 seat_preference_agent run prompt=confirm\n",
      "11:01:36.774   preparing model and tools run_step=1\n",
      "11:01:36.775   model request\n",
      "11:01:38.705   handle model response\n",
      "Could not understand seat preference.Please try again.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">What seat would you like?: </pre>\n"
      ],
      "text/plain": [
       "What seat would you like?: "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11:02:15.549 seat_preference_agent run prompt=front\n",
      "11:02:15.550   preparing model and tools run_step=1\n",
      "11:02:15.550   model request\n",
      "11:02:17.293   handle model response\n",
      "Confirming ticket on  flight flight_details=FlightDetails(flight_number='NYC-LA101', price='$250', origin='SFO', destination='ANC', date=datetime.date(2025, 1, 10)) seat=SeatPreference(row=1, seat='A')...\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "from dataclasses import dataclass\n",
    "from typing import Literal\n",
    "\n",
    "import logfire\n",
    "from pydantic import BaseModel,Field\n",
    "\n",
    "from rich.prompt import Prompt\n",
    "\n",
    "from pydantic_ai import Agent,ModelRetry,RunContext\n",
    "from pydantic_ai.messages import ModelMessage\n",
    "from pydantic_ai.settings import UsageLimits\n",
    "from pydantic_ai.result import Usage\n",
    "\n",
    "\n",
    "logfire.configure(send_to_logfire='if-token-present')\n",
    "\n",
    "class FlightDetails(BaseModel):\n",
    "    \"\"\"Details of the most suitable flight\"\"\"\n",
    "    flight_number:str\n",
    "    price:str\n",
    "    origin:str = Field(description='Three letter airport code')\n",
    "    destination:str = Field(description=\"Three letter airport code\")\n",
    "    date:datetime.date\n",
    "\n",
    "class NoFlightFound(BaseModel):\n",
    "    \"When no valid flight found\"\n",
    "\n",
    "@dataclass\n",
    "class Deps:\n",
    "    web_page_text:str\n",
    "    req_origin:str\n",
    "    req_destination:str\n",
    "    req_date:datetime.date\n",
    "\n",
    "\n",
    "\n",
    "search_agent = Agent[Deps,FlightDetails|NoFlightFound](\n",
    "    'groq:llama-3.1-70b-versatile',\n",
    "    result_type=FlightDetails | NoFlightFound,\n",
    "    retries=4,\n",
    "    system_prompt=(\n",
    "        'Your job is to find the cheapest flight for the user on the given date'\n",
    "    )\n",
    ")\n",
    "\n",
    "extraction_agent = Agent(\n",
    "    'groq:llama-3.1-70b-versatile',\n",
    "    result_type=list[FlightDetails],\n",
    "    system_prompt='Extract all the flight details from the given text.'\n",
    ")\n",
    "\n",
    "@search_agent.tool\n",
    "async def extract_flights(ctx:RunContext[Deps]) -> list[FlightDetails]:\n",
    "    \"\"\"Get details of all flights\"\"\"\n",
    "    result = await extraction_agent.run(ctx.deps.web_page_text,usage=ctx.usage)\n",
    "    logfire.info('Found {flight_count}',flight_count=len(result.data))\n",
    "    return result.data\n",
    "\n",
    "@search_agent.result_validator\n",
    "async def validate_result(\n",
    "    ctx:RunContext[Deps] , result:FlightDetails |NoFlightFound\n",
    ") -> FlightDetails |NoFlightFound:\n",
    "    \"\"\"Procedural validation that the flight meets the constraints \"\"\"\n",
    "    if isinstance(result,NoFlightFound):\n",
    "        return result\n",
    "    errors: list[str] = []\n",
    "\n",
    "    if result.origin != ctx.deps.req_origin:\n",
    "        errors.append(\n",
    "            f'Flight should have origin {ctx.deps.req_origin} , not {result.origin}'\n",
    "        )\n",
    "\n",
    "    if result.destination != ctx.deps.req_destination:\n",
    "        errors.append(\n",
    "            f'Flight should have destination {ctx.deps.req_destination} , not {result.destination}'\n",
    "        )\n",
    "\n",
    "    if result.date != ctx.deps.req_date:\n",
    "        errors.append(f'Flight should be on {ctx.deps.req_date} , not {result.date}')\n",
    "\n",
    "    if errors:\n",
    "        raise ModelRetry(\"\\n\".join(errors))\n",
    "    else:\n",
    "        return result\n",
    "\n",
    "class SeatPreference(BaseModel):\n",
    "    row : int =Field(ge=1 , le=30)\n",
    "    seat: Literal['A','B','C','D','E','F']\n",
    "\n",
    "class Failed(BaseModel):\n",
    "    \"Unable to extract a seat selection\"\n",
    "\n",
    "seat_preference_agent =Agent[\n",
    "    None,SeatPreference|Failed\n",
    "](\n",
    "    'gemini-1.5-flash',\n",
    "    result_type=SeatPreference|Failed,\n",
    "    system_prompt=(\n",
    "        \"Extract the user's seat preference.\"\n",
    "        \"Seats A and F are window seats.\"\n",
    "        \"Row 1 is the front row and has extra leg room. \"\n",
    "        \"Row 14, and 20 also have extra leg room.\"\n",
    "    )\n",
    ")\n",
    "\n",
    "flights_web_page = \"\"\"\n",
    "1. Flight SFO-AK123\n",
    "- Price: $350\n",
    "- Origin: San Francisco International Airport (SFO)\n",
    "- Destination: Ted Stevens Anchorage International Airport (ANC)\n",
    "- Date: January 10, 2025\n",
    "\n",
    "2. Flight SFO-AK456\n",
    "- Price: $370\n",
    "- Origin: San Francisco International Airport (SFO)\n",
    "- Destination: Fairbanks International Airport (FAI)\n",
    "- Date: January 10, 2025\n",
    "\n",
    "3. Flight SFO-AK789\n",
    "- Price: $400\n",
    "- Origin: San Francisco International Airport (SFO)\n",
    "- Destination: Juneau International Airport (JNU)\n",
    "- Date: January 20, 2025\n",
    "\n",
    "4. Flight NYC-LA101\n",
    "- Price: $250\n",
    "- Origin: San Francisco International Airport (SFO)\n",
    "- Destination: Ted Stevens Anchorage International Airport (ANC)\n",
    "- Date: January 10, 2025\n",
    "\n",
    "5. Flight CHI-MIA202\n",
    "- Price: $200\n",
    "- Origin: Chicago O'Hare International Airport (ORD)\n",
    "- Destination: Miami International Airport (MIA)\n",
    "- Date: January 12, 2025\n",
    "\n",
    "6. Flight BOS-SEA303\n",
    "- Price: $120\n",
    "- Origin: Boston Logan International Airport (BOS)\n",
    "- Destination: Ted Stevens Anchorage International Airport (ANC)\n",
    "- Date: January 12, 2025\n",
    "\n",
    "7. Flight DFW-DEN404\n",
    "- Price: $150\n",
    "- Origin: Dallas/Fort Worth International Airport (DFW)\n",
    "- Destination: Denver International Airport (DEN)\n",
    "- Date: January 10, 2025\n",
    "\n",
    "8. Flight ATL-HOU505\n",
    "- Price: $180\n",
    "- Origin: Hartsfield-Jackson Atlanta International Airport (ATL)\n",
    "- Destination: George Bush Intercontinental Airport (IAH)\n",
    "- Date: January 10, 2025\n",
    "\"\"\"\n",
    "\n",
    "usage_limits = UsageLimits(request_limit=15)\n",
    "\n",
    "\n",
    "async def main():\n",
    "\n",
    "    while True:\n",
    "\n",
    "        deps = Deps(\n",
    "            web_page_text=flights_web_page,\n",
    "            req_origin='SFO',\n",
    "            req_destination='ANC',\n",
    "            req_date=datetime.date(2025,1,10)\n",
    "        )\n",
    "        message_history:list[ModelMessage] |None  =None\n",
    "        usage:Usage = Usage()\n",
    "        result = await search_agent.run(\n",
    "            f'Find me a flight from {deps.req_origin} to {deps.req_destination} on {deps.req_date}',\n",
    "            deps =deps,\n",
    "            usage=usage,\n",
    "            message_history=message_history\n",
    "        )\n",
    "\n",
    "        if isinstance(result.data,NoFlightFound):\n",
    "            print('No flights found')\n",
    "            break\n",
    "        else:\n",
    "            flight=result.data\n",
    "            print(f'Flight found: {flight}')\n",
    "            answer =Prompt.ask(\n",
    "                'Do you want to confirm this flight or keep searching? (confirm/search)',\n",
    "                choices = ['confirm','search',''],\n",
    "                show_choices=False\n",
    "            )\n",
    "\n",
    "            if answer=='confirm':\n",
    "                seat =await find_seat(usage)\n",
    "                await confirm_tickets(flight,seat)\n",
    "                break\n",
    "            else:\n",
    "                message_history= result.all_messages()\n",
    "\n",
    "\n",
    "async def find_seat(usage:Usage)-> SeatPreference:\n",
    "    message_history:list[ModelMessage]|None = None\n",
    "    while True:\n",
    "        answer= Prompt.ask('What seat would you like?')\n",
    "\n",
    "        result = await seat_preference_agent.run(\n",
    "            answer,\n",
    "            message_history=message_history,\n",
    "            usage=usage,\n",
    "            usage_limits=usage_limits\n",
    "        )\n",
    "        if isinstance(result.data,SeatPreference):\n",
    "            return result.data\n",
    "        else:\n",
    "            print('Could not understand seat preference.Please try again.')\n",
    "            message_history=result.all_messages()\n",
    "\n",
    "async def confirm_tickets(flight_details:FlightDetails ,seat:SeatPreference):\n",
    "    print(f'Confirming ticket on  flight {flight_details=!r} {seat=!r}...')\n",
    "\n",
    "\n",
    "await main()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
